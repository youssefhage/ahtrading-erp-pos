services:
  db:
    image: postgres:15
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U \"$POSTGRES_USER\" -d \"$POSTGRES_DB\""]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 20s
    networks:
      - internal

  api:
    build:
      # This file lives in `deploy/`, so set context to repo root.
      context: ..
      dockerfile: backend/Dockerfile
    restart: unless-stopped
    environment:
      APP_ENV: ${APP_ENV:-prod}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      # Non-superuser app role used by API/worker so RLS is actually enforced.
      APP_DB_USER: ${APP_DB_USER}
      APP_DB_PASSWORD: ${APP_DB_PASSWORD}
      APP_DATABASE_URL: postgresql://${APP_DB_USER}:${APP_DB_PASSWORD}@db:5432/${POSTGRES_DB}
      # Cloud endpoint for edge -> cloud replication (optional but recommended on cloud).
      EDGE_SYNC_KEY: ${EDGE_SYNC_KEY:-}
      # Safety: do not auto-create/reset admin users in production.
      BOOTSTRAP_ADMIN: ${BOOTSTRAP_ADMIN:-0}
      BOOTSTRAP_ADMIN_EMAIL: ${BOOTSTRAP_ADMIN_EMAIL:-}
      BOOTSTRAP_ADMIN_PASSWORD: ${BOOTSTRAP_ADMIN_PASSWORD:-}
      BOOTSTRAP_ADMIN_RESET_PASSWORD: ${BOOTSTRAP_ADMIN_RESET_PASSWORD:-0}
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health').read()"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 180s
    command:
      - sh
      - -lc
      - |
        set -euo pipefail
        attempt=0
        until backend/scripts/init_db.sh; do
          attempt=$$((attempt+1))
          if [ "$$attempt" -ge 60 ]; then
            echo "init_db failed after $$attempt attempts" >&2
            exit 1
          fi
          echo "init_db failed; retrying in 2s ($$attempt/60)..." >&2
          sleep 2
        done
        exec uvicorn backend.app.main:app --host 0.0.0.0 --port 8000
    networks:
      - internal
      - dokploy

  worker:
    build:
      context: ..
      dockerfile: backend/Dockerfile
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      APP_DB_USER: ${APP_DB_USER}
      APP_DB_PASSWORD: ${APP_DB_PASSWORD}
      APP_DATABASE_URL: postgresql://${APP_DB_USER}:${APP_DB_PASSWORD}@db:5432/${POSTGRES_DB}
    depends_on:
      api:
        condition: service_healthy
    command:
      - sh
      - -lc
      - |
        set -euo pipefail
        attempt=0
        until backend/scripts/init_db.sh; do
          attempt=$$((attempt+1))
          if [ "$$attempt" -ge 60 ]; then
            echo "init_db failed after $$attempt attempts" >&2
            exit 1
          fi
          echo "init_db failed; retrying in 2s ($$attempt/60)..." >&2
          sleep 2
        done
        exec python3 -m backend.workers.worker_service --db "$$APP_DATABASE_URL"
    networks:
      - internal

  admin:
    build:
      context: ..
      dockerfile: apps/admin/Dockerfile
    restart: unless-stopped
    environment:
      API_PROXY_TARGET: http://api:8000
    depends_on:
      api:
        condition: service_healthy
    networks:
      - internal
      - dokploy

volumes:
  pgdata:

networks:
  # Internal per-compose network: safe for service-name DNS like `db`, `api`, etc.
  internal:
    driver: bridge
  # Shared dokploy/traefik network for inbound routing.
  # Dokploy sets this up; we attach only the services that need to be routed.
  dokploy:
    external: true
    name: dokploy-network
